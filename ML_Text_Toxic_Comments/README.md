# Выявление токсичных комментариев

## Задача
Вы работаете в интернет-магазине. Руководство решило запустить новый сервис, который позволяет пользователям редактировать и дополнять описания товаров, то есть клиенты предлагают свои собственные правки, а также имеют возможность комментировать другие. Для корректного функционирования данного сервиса необходимо разработать инструмент, который будет выявлять токсичные комментарии и отправлять их на модерацию. 

Ваша задача - обучить модель классификации, способную распознавать позитивные и негативные комментарии. Для этого у нас есть набор размеченных текстов.

Целевая метрика - F1-мера. Задача считается выполненной, если ее значение на тестовой выборке не меньше 0.75.

В процессе выполнения проекта необходимо:
- Загрузить и подготовить данные к анализу (удалить ненужные символы, провести лемматизацию, векторизацию и т.д.).
- Разбить данные на обучающую и тестовую выборки. Размер тестовой выборки выбрать самостоятельно.
- Обучить разные модели, оптимизировать их гиперпараметры.
- Сравнить производительность моделей. Сделать выводы.

## Имеющиеся данные
В нашем распоряжении размеченные комментарии пользователей на английском языке. Столбец *text* содержит текст комментария, а *toxic* — целевой признак.

## Используемые библиотеки
*pandas*

*re*

*nltk*

*sklearn*

*scipy*

*lightgbm*