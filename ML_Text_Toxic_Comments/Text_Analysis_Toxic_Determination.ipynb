{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключим необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rus95\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from scipy.stats import loguniform\n",
    "from scipy.stats import uniform\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и ознакомление с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим набор данных и посмотрим на первые 5 строк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение целевого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898321\n",
       "1    0.101679\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- В наборе данных 159571 строка, пропусков нет.\n",
    "- Имеем дело с английскими текстами.\n",
    "- Имеется дисбаланс классов. Токсичных комментариев всего 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед лемматизацией удалим из текстов все ненужные символы, оставим лишь буквы латинского алфавита и пробелы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.apply(lambda x: ' '.join(re.sub(r'[^a-zA-Z ]', ' ', x).split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим каждый текст строкой, состоящей из лемм его слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "corpus = corpus.apply(lambda x: ' '.join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем все тексты к нижнему регистру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на первые 5 строк до и после преобразований."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  D'aww! He matches this background colour I'm s...   \n",
       "2  Hey man, I'm really not trying to edit war. It...   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4  You, sir, are my hero. Any chance you remember...   \n",
       "\n",
       "                                                text  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d aww he match this background colour i m seem...  \n",
       "2  hey man i m really not trying to edit war it s...  \n",
       "3  more i can t make any real suggestion on impro...  \n",
       "4  you sir are my hero any chance you remember wh...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df['text'], corpus], axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем данные на обучающую и тестовую выборки в соотношении 80:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(corpus, \n",
    "                                                                            df['toxic'], \n",
    "                                                                            test_size=0.2, \n",
    "                                                                            random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим размеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127656,)\n",
      "(31915,)\n",
      "(127656,)\n",
      "(31915,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_train.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также проверим долю \"токсичных\" комментариев в обеих выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10168734724572288\n",
      "0.10164499451668495\n"
     ]
    }
   ],
   "source": [
    "print(target_train.mean())\n",
    "print(target_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение произведено корректно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установим стоп-слова для английского языка для дальнейшей векторизации текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "1. Данные были загружены. Имеем 143916 строк с английским текстом, и значение целевого признака (токсичен комментарий или нет) для каждого текста.\n",
    "2. Из текстов были удалены лишние символы, а также проведена лемматизация.\n",
    "3. Данные были разбиты на обучающую и тестовую выборки в соотношении 80:20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим несколько моделей, а также оптимизируем их гиперпараметры с помощью техники Randomized Search. \n",
    "\n",
    "Интересующая нас метрика - F1-мера. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы кросс-валидация была выполнена корректно, создадим пайплайн, состоящий из двух шагов: векторизация и сама модель. Это нужно, чтобы при каждом разбиении валидации векторизация производилась лишь по обучающей выборке.\n",
    "\n",
    "Векторизацию выполним с помощью техники TF-IDF, будем использовать лишь униграммы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_log_reg = Pipeline([('vectorizer', TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 1))), \n",
    "                         ('log_reg', LogisticRegression(class_weight='balanced', max_iter=1000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_log_reg = {\n",
    "    'log_reg__C' : loguniform(0.01, 100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Wall time: 3min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('vectorizer',\n",
       "                                              TfidfVectorizer(stop_words={'a',\n",
       "                                                                          'about',\n",
       "                                                                          'above',\n",
       "                                                                          'after',\n",
       "                                                                          'again',\n",
       "                                                                          'against',\n",
       "                                                                          'ain',\n",
       "                                                                          'all',\n",
       "                                                                          'am',\n",
       "                                                                          'an',\n",
       "                                                                          'and',\n",
       "                                                                          'any',\n",
       "                                                                          'are',\n",
       "                                                                          'aren',\n",
       "                                                                          \"aren't\",\n",
       "                                                                          'as',\n",
       "                                                                          'at',\n",
       "                                                                          'be',\n",
       "                                                                          'because',\n",
       "                                                                          'been',\n",
       "                                                                          'before',\n",
       "                                                                          'being',\n",
       "                                                                          'below',\n",
       "                                                                          'between',\n",
       "                                                                          'both',\n",
       "                                                                          'but',\n",
       "                                                                          'by',\n",
       "                                                                          'can',\n",
       "                                                                          'couldn',\n",
       "                                                                          \"couldn't\", ...})),\n",
       "                                             ('log_reg',\n",
       "                                              LogisticRegression(class_weight='balanced',\n",
       "                                                                 max_iter=1000))]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'log_reg__C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000154ED9AF520>},\n",
       "                   random_state=42, scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search_lr = RandomizedSearchCV(\n",
    "    estimator=pipe_log_reg,\n",
    "    param_distributions=params_log_reg,\n",
    "    n_iter=20,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rand_search_lr.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучший параметр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log_reg__C': 6.796578090758152}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search_lr.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшее значение F1-меры на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7598871352929937"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_log_reg_cv = rand_search_lr.best_score_\n",
    "f1_log_reg_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним наилучшую модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = rand_search_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в предыдущем случае, создаем пайплайн."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([('vectorizer', TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 1))), \n",
    "                    ('random_forest', RandomForestClassifier(class_weight='balanced', random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случайном лесу будем калибровать глубину дерева, их количество, а также ограничения на сплиты и листы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rand_forest = {\n",
    "    'random_forest__max_depth' : range(6, 18),\n",
    "    'random_forest__n_estimators' : range(5, 200),\n",
    "    'random_forest__min_samples_split' : range(2, 8),\n",
    "    'random_forest__min_samples_leaf' : range(1, 6)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Wall time: 2min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('vectorizer',\n",
       "                                              TfidfVectorizer(stop_words={'a',\n",
       "                                                                          'about',\n",
       "                                                                          'above',\n",
       "                                                                          'after',\n",
       "                                                                          'again',\n",
       "                                                                          'against',\n",
       "                                                                          'ain',\n",
       "                                                                          'all',\n",
       "                                                                          'am',\n",
       "                                                                          'an',\n",
       "                                                                          'and',\n",
       "                                                                          'any',\n",
       "                                                                          'are',\n",
       "                                                                          'aren',\n",
       "                                                                          \"aren't\",\n",
       "                                                                          'as',\n",
       "                                                                          'at',\n",
       "                                                                          'be',\n",
       "                                                                          'because',\n",
       "                                                                          'been',\n",
       "                                                                          'before',\n",
       "                                                                          'being',\n",
       "                                                                          'below',\n",
       "                                                                          'between',\n",
       "                                                                          'both',\n",
       "                                                                          'but',\n",
       "                                                                          'by',\n",
       "                                                                          'can',\n",
       "                                                                          'couldn',\n",
       "                                                                          \"couldn't\", ...})),\n",
       "                                             ('random_forest',\n",
       "                                              RandomForestClassifier(class_weight='balanced',\n",
       "                                                                     random_state=42))]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'random_forest__max_depth': range(6, 18),\n",
       "                                        'random_forest__min_samples_leaf': range(1, 6),\n",
       "                                        'random_forest__min_samples_split': range(2, 8),\n",
       "                                        'random_forest__n_estimators': range(5, 200)},\n",
       "                   random_state=42, scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search_rf = RandomizedSearchCV(\n",
    "    estimator=pipe_rf,\n",
    "    param_distributions=params_rand_forest,\n",
    "    n_iter=20,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rand_search_rf.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшие параметры модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_forest__n_estimators': 190,\n",
       " 'random_forest__min_samples_split': 4,\n",
       " 'random_forest__min_samples_leaf': 1,\n",
       " 'random_forest__max_depth': 17}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search_rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшая производительность модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38906837488718793"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_random_forest_cv = rand_search_rf.best_score_\n",
    "f1_random_forest_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним самую успешную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = rand_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lgbm = Pipeline([('vectorizer', TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 1))), \n",
    "                      ('lgbm', LGBMClassifier(class_weight='balanced', random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае градиентного бустинга будем калибровать глубину деревьев, их количество, скорость обучения и коэффициент L2-регуляризации. Будем использовать библиотеку LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgbm = {\n",
    "    'lgbm__max_depth' : range(3, 6),\n",
    "    'lgbm__n_estimators' : range(5, 350),\n",
    "    'lgbm__learning_rate' : loguniform(0.0001, 0.5),\n",
    "    'lgbm__reg_lambda' : uniform(0.01, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Wall time: 20min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('vectorizer',\n",
       "                                              TfidfVectorizer(stop_words={'a',\n",
       "                                                                          'about',\n",
       "                                                                          'above',\n",
       "                                                                          'after',\n",
       "                                                                          'again',\n",
       "                                                                          'against',\n",
       "                                                                          'ain',\n",
       "                                                                          'all',\n",
       "                                                                          'am',\n",
       "                                                                          'an',\n",
       "                                                                          'and',\n",
       "                                                                          'any',\n",
       "                                                                          'are',\n",
       "                                                                          'aren',\n",
       "                                                                          \"aren't\",\n",
       "                                                                          'as',\n",
       "                                                                          'at',\n",
       "                                                                          'be',\n",
       "                                                                          'because',\n",
       "                                                                          'been',\n",
       "                                                                          'before',\n",
       "                                                                          'being',\n",
       "                                                                          'below',\n",
       "                                                                          'between',\n",
       "                                                                          'both',\n",
       "                                                                          'but',\n",
       "                                                                          'by',\n",
       "                                                                          'can',\n",
       "                                                                          'couldn',\n",
       "                                                                          \"couldn't\", ...})),\n",
       "                                             ('lgbm',\n",
       "                                              LGBMClassifier(class_weight='b...,\n",
       "                                                             random_state=42))]),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'lgbm__learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000154EDEFEA90>,\n",
       "                                        'lgbm__max_depth': range(3, 6),\n",
       "                                        'lgbm__n_estimators': range(5, 350),\n",
       "                                        'lgbm__reg_lambda': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000154EDBD5A90>},\n",
       "                   random_state=42, scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search_lgbm = RandomizedSearchCV(\n",
    "    estimator=pipe_lgbm,\n",
    "    param_distributions=params_lgbm,\n",
    "    n_iter=50,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rand_search_lgbm.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшие параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lgbm__learning_rate': 0.409703267332127,\n",
       " 'lgbm__max_depth': 4,\n",
       " 'lgbm__n_estimators': 347,\n",
       " 'lgbm__reg_lambda': 2.7964646423661144}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search_lgbm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшее значение F1-меры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7413839578965877"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_lgbm_cv = rand_search_lgbm.best_score_\n",
    "f1_lgbm_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним наилучшую модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = rand_search_lgbm.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение моделй"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сведем полученные на кросс-валидации результаты в одну таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1 on cross-validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.759887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.389068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.741384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  f1 on cross-validation\n",
       "0  logistic regression                0.759887\n",
       "1        random forest                0.389068\n",
       "2             LightGBM                0.741384"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame([\n",
    "    ['logistic regression', f1_log_reg_cv],\n",
    "    ['random forest', f1_random_forest_cv],\n",
    "    ['LightGBM', f1_lgbm_cv]\n",
    "], columns=['model', 'f1 on cross-validation']\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Случайный лес показал самую худшую производительность на кросс-валидации.\n",
    "- Лучше всех себя проявила логистическая регрессия. Градиентный бустинг показал сравнимые результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем предсказания на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = log_reg.predict(features_test)\n",
    "y_pred_rf = random_forest.predict(features_test)\n",
    "y_pred_lgbm = lgbm.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем F1-меру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_log_reg_test = f1_score(target_test, y_pred_lr)\n",
    "f1_random_forest_test = f1_score(target_test, y_pred_rf)\n",
    "f1_lgbm_test = f1_score(target_test, y_pred_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим полученные значения в таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['f1 on test'] = [f1_log_reg_test, f1_random_forest_test, f1_lgbm_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1 on cross-validation</th>\n",
       "      <th>f1 on test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.759887</td>\n",
       "      <td>0.765383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.389068</td>\n",
       "      <td>0.384524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.741384</td>\n",
       "      <td>0.747125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  f1 on cross-validation  f1 on test\n",
       "0  logistic regression                0.759887    0.765383\n",
       "1        random forest                0.389068    0.384524\n",
       "2             LightGBM                0.741384    0.747125"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такая же ситуация, как и на кросс-валидации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также посчитаем точность, полноту и accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['recall on test'] = [recall_score(target_test, y_pred_lr), \n",
    "                             recall_score(target_test, y_pred_rf), \n",
    "                             recall_score(target_test, y_pred_lgbm)]\n",
    "\n",
    "results['precision on test'] = [precision_score(target_test, y_pred_lr), \n",
    "                                precision_score(target_test, y_pred_rf), \n",
    "                                precision_score(target_test, y_pred_lgbm)]\n",
    "\n",
    "results['accuracy on test'] = [accuracy_score(target_test, y_pred_lr), \n",
    "                               accuracy_score(target_test, y_pred_rf), \n",
    "                               accuracy_score(target_test, y_pred_lgbm)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1 on cross-validation</th>\n",
       "      <th>f1 on test</th>\n",
       "      <th>recall on test</th>\n",
       "      <th>precision on test</th>\n",
       "      <th>accuracy on test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.759887</td>\n",
       "      <td>0.765383</td>\n",
       "      <td>0.830148</td>\n",
       "      <td>0.709992</td>\n",
       "      <td>0.948269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.389068</td>\n",
       "      <td>0.384524</td>\n",
       "      <td>0.845561</td>\n",
       "      <td>0.248843</td>\n",
       "      <td>0.724863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.741384</td>\n",
       "      <td>0.747125</td>\n",
       "      <td>0.831073</td>\n",
       "      <td>0.678580</td>\n",
       "      <td>0.942817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  f1 on cross-validation  f1 on test  recall on test  \\\n",
       "0  logistic regression                0.759887    0.765383        0.830148   \n",
       "1        random forest                0.389068    0.384524        0.845561   \n",
       "2             LightGBM                0.741384    0.747125        0.831073   \n",
       "\n",
       "   precision on test  accuracy on test  \n",
       "0           0.709992          0.948269  \n",
       "1           0.248843          0.724863  \n",
       "2           0.678580          0.942817  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все три модели имеют сравнимую довольно высокую полноту, однако случайный лес имеет слишком низкую точность, что говорит о том, что модель слишком часто предсказывает класс \"1\", когда она этого делать не должна, т.е. высока доля ложно-положительных ответов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По условию задачи, нужно получить F1-меру выше 0.75, что и было достигнуто с помощью логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Исходные текстовые данные были очищены от ненужных символов, затем лемматизированы и переведены в векторы с помощью техники TF-IDF.\n",
    "- Три модели машинного обучения были обучены: логистическая регрессия, случайный лес и градиентный бустинг. Были оптимизированы их гиперпараметры.\n",
    "- Наивысшую F1-меру на кросс-валидации и тесте показала логистическая регрессия, ее значение превышает заданные заказчиком 0.75, так что можем считать нашу цель достигнутой.\n",
    "- Градиентный бустинг показал неплохие результаты, но не смог достичь отметки 0.75. Возможно, этого бы удалось добиться, если бы мы использовали больше итераций на этапе поиска оптимальных гиперпараметров, однако из-за болього размера признакого пространства это бы заняло много времени.\n",
    "- Случайный лес показал наихудшие результаты. Дело в том, что модель слишком часто предсказывает класс \"1\", из-за чего высока доля ложно-положительных ответов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
